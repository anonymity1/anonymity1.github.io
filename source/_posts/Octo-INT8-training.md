---
title: Octo INT8 training
date: 2021-09-29 21:40:55
tags: 论文阅读
---

Octo: INT8 Training with Loss-aware Compensation and Backward Quantization for Tiny On-device Learning (ATC 2021)

背景：系统，单设备，边缘+训练+量化。思路亮点：引入LAC+PRC。系统亮点：低依赖，只需python基本库。

<!-- more -->

## 研究背景

边缘端高效模型训练是实现边缘智能的关键环节。已有研究对边缘端**数据收集**和**推理加速**进行了深入探讨，其中**量化**（即将神经网络模型中的参数权重从FP32转为低精度格式数据，从而实现存储和计算开销降低的方法）是数据中心实现高效模型推理和训练的一种有效方案。

## 研究问题

但是目前将已有的模型量化方法应用到轻量级设备模型训练存在四个问题

- 部分研究工作适用于推理场景，不适用模型训练；

- 部分研究工作只适用特殊网络结构，因为采用了极低比特设计（比如4bit存储）；

- 不能够在训练阶段实现硬件层面实际加速（理论可以，实际不行）；

- 没有对训练阶段算法做充分优化，无法适应低资源设备。

总之，已有的模型量化方法可适用在边缘端推理，或者理论上可行，但是实际不适用边缘端模型训练加速。因此要设计一种能够**实际应用在边缘侧**的**模型训练**的**量化加速**方案。

## 系统设计中的挑战和思路

- 如何充分利用硬件算力以及保证在不同边缘的通用性？（设计）

    将统一的8位量化引入卷积运算、仿射模块、激活函数和梯度计算。数据量化涵盖前向和后向传递，因此可以加速整个迭代。卷积模块、仿射模块均基于numpy库编写，确保通用性。

- 量化会降低前向计算和后向计算的精度，如何保证精度降低范围可接受？（精度）

    通过整体调整前向和后向传递的中间结果来保持模型的准确性。在前向传递中，提出了损失感知补偿(LAC)方法并设计了一个新的神经网络组件，称为补偿层，以填补量化张量算法引起的误差差距。补偿层内部的参数根据网络损失进行优化，为了提高更新效率，引入了补偿参数的L2正则化项。在反向传播中，提出了参数化范围裁剪(PRC)方法来限制量化梯度的变换域。

- 引入新的层是否会带来额外计算开销，从而抵消量化带来的性能优化？（系统开销）

    以INT8格式保留所有参数和中间导数。可以有效地减少了峰值内存占用并节省了访问参数缓存的存储成本。对于上一个问题中提到的LAC和PRC可能会产生额外的开销，将补偿项从使用FP32张量的更高次多项式转换为仅依赖于卷积层输出的仿射运算，从而限制补偿和裁剪的计算成本。

## 前向LAC层和后向PRC方法

量化误差（补偿）表达式：

![](/img/Octo/lac.png)

补偿层设计代码：

```python
class Compensation:
    def __init__(self, alpha, mu, offset, enable_compensation_clipping=False, layer_id='Compensation'):
        ...

    def forward(self, x):
        out = x + self.alpha * self.mu + self.offset
        self.fp_out_before_clipping = out

        if self.enable_compensation_clipping:
            out = self.parametrized_range_clipping(out)

        return out

    def backward(self, dout):
        ...
```

含有误差$L_2$范数正则项的损失函数

![](/img/Octo/lac2.png)

在执行反向传播过程中，最终优化的目标函数变更为上式。

在后向传播过程当中，也可以使用梯度量化的方法，因为梯度也可以抽象为向量点积，遵循链式法则。但是后向传播计算梯度过程不能通过添加补偿层的方法降低量化误差。为了降低梯度的量化误差，关键在于降低零点偏移，通过对具有不同数值分布的张量确定不同量化范围，从而使零点偏移降低。并根据张量的数值分布通常呈钟形这一特点，启发性地将量化范围缩小为原来的0.95。

```python
def parametrized_range_clipping(self, tensor, z=2.576):
    n = tensor.size
    if n == 0:
        return tensor

    self.clip_max = 0.95 * np.max(tensor)
    self.clip_min = 0.95 * np.min(tensor)

    return np.clip(tensor, self.clip_min, self.clip_max)
```

## 复现和思考

- 由于基于numpy库编写，能够实现不同边缘平台的推理和训练，通用性可以保证。

- 实验数据集为MNIST，CIFAR10小数据集，完成任务是图片分类，属于比较简单的机器学习任务。代码支持的算子主要是卷积、仿射和部分激活函数。比较的基线是基于其自身框架实现的量化算法。可以考虑根据该库添加不同算子，实现不同模型，或者进一步改进其性能。

- 目前能够在GPU和NPU上顺利运行，对于不同平台支持的优化方案比较还需要进一步验证。
